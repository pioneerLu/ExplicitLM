#!/bin/bash
# SFT è®­ç»ƒå¯åŠ¨è„šæœ¬ï¼šä½¿ç”¨ GPU 6 å’Œ 7

# ========== é…ç½®åŒºåŸŸ ==========
# è®¾ç½®GPUå¯è§è®¾å¤‡
export CUDA_VISIBLE_DEVICES=6,7

# è®¾ç½®PyTorchå†…å­˜åˆ†é…é…ç½®
export PYTORCH_ALLOC_CONF=expandable_segments:True

# è¿›å…¥é¡¹ç›®ç›®å½•
cd /data2/zengzheni/lvchangwei/new_repo/ExplicitLM

# ä¼˜å…ˆä½¿ç”¨ uv
if command -v uv &> /dev/null; then
    export PATH="$HOME/.local/bin:$PATH"
    echo "âœ… ä½¿ç”¨ uv è¿è¡Œè®­ç»ƒ"
    ACCELERATE_CMD="uv run accelerate launch --config_file accelerate_config.yaml"
elif [ -f ".venv/bin/activate" ]; then
    source .venv/bin/activate
    echo "âœ… å·²æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ: $(which python)"
    ACCELERATE_CMD="accelerate launch --config_file accelerate_config.yaml"
elif [ -f "venv/bin/activate" ]; then
    source venv/bin/activate
    echo "âœ… å·²æ¿€æ´»venvè™šæ‹Ÿç¯å¢ƒ: $(which python)"
    ACCELERATE_CMD="accelerate launch --config_file accelerate_config.yaml"
else
    echo "âš ï¸  æœªæ‰¾åˆ°è™šæ‹Ÿç¯å¢ƒï¼Œä½¿ç”¨ç³»ç»ŸPython: $(which python)"
    ACCELERATE_CMD="accelerate launch --config_file accelerate_config.yaml"
fi

# æ˜¾ç¤ºGPUä¿¡æ¯
echo "=========================================="
echo "ä½¿ç”¨GPU: 6, 7"
echo "=========================================="
nvidia-smi --query-gpu=index,name,memory.total,memory.free --format=csv,noheader | grep -E "^[67],"

# ========== è®­ç»ƒé…ç½® ==========
# è¯·æ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ä»¥ä¸‹è·¯å¾„
QWEN3_MODEL_PATH="/data2/zengzheni/lvchangwei/new_repo/Qwen/models/Qwen3-4b"
CACHE_PATH="data/cache/knowledge_cache.pt"
PRETRAINED_MODEL_PATH="out/pretrain_latest.pth"
SFT_DATASET_PATH="sft_data/omcq_trex_sft.jsonl"
SFT_VAL_DATASET_PATH="data/benchmarks/eval_data.json"

# è®­ç»ƒè¶…å‚æ•°
LEARNING_RATE=5e-5
BATCH_SIZE=4
ACCUMULATION_STEPS=32
EPOCHS=3
MAX_SEQ_LEN=512

echo ""
echo "=========================================="
echo "ğŸš€ å¯åŠ¨ SFT è®­ç»ƒï¼ˆOMCQ æ•°æ®ï¼‰"
echo "=========================================="
echo ""
echo "é…ç½®ï¼š"
echo "  - Qwen3 æ¨¡å‹: $QWEN3_MODEL_PATH"
echo "  - Cache è·¯å¾„: $CACHE_PATH"
echo "  - é¢„è®­ç»ƒæ¨¡å‹: $PRETRAINED_MODEL_PATH"
echo "  - è®­ç»ƒæ•°æ®: $SFT_DATASET_PATH"
echo "  - éªŒè¯æ•°æ®: $SFT_VAL_DATASET_PATH"
echo "  - å­¦ä¹ ç‡: $LEARNING_RATE"
echo "  - æ‰¹æ¬¡å¤§å°: $BATCH_SIZE"
echo "  - æ¢¯åº¦ç´¯ç§¯: $ACCUMULATION_STEPS"
echo "  - è®­ç»ƒè½®æ•°: $EPOCHS"
echo "  - æœ€å¤§åºåˆ—é•¿åº¦: $MAX_SEQ_LEN"
echo "  - DeepSpeed Stage: 3 (ZeRO-3)"
echo "  - Checkpoint ä¿å­˜ç›®å½•: out/"
echo ""

# æ£€æŸ¥å¿…è¦æ–‡ä»¶
if [ ! -f "$SFT_DATASET_PATH" ]; then
    echo "âŒ é”™è¯¯: SFT è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: $SFT_DATASET_PATH"
    echo "è¯·å…ˆè¿è¡Œæ•°æ®è½¬æ¢è„šæœ¬:"
    echo "  python3 scripts/convert_omcq_to_sft.py --input sft_data/omcq_trex_data.json --output $SFT_DATASET_PATH"
    exit 1
fi

if [ ! -f "$PRETRAINED_MODEL_PATH" ]; then
    echo "âš ï¸  è­¦å‘Š: é¢„è®­ç»ƒæ¨¡å‹ä¸å­˜åœ¨: $PRETRAINED_MODEL_PATH"
    echo "å°†ä»å¤´å¼€å§‹è®­ç»ƒï¼ˆä¸æ¨èï¼‰"
fi

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
mkdir -p out

# å¯åŠ¨è®­ç»ƒ
echo "=========================================="
echo "å¼€å§‹è®­ç»ƒ..."
echo "=========================================="
echo ""

$ACCELERATE_CMD 2_sft.py \
    +model.qwen3_model_path="$QWEN3_MODEL_PATH" \
    model.cache_path="$CACHE_PATH" \
    model.recompute_cache=False \
    model.database_init_path="" \
    model.max_seq_len="$MAX_SEQ_LEN" \
    dataset.sft_dataset_path="$SFT_DATASET_PATH" \
    dataset.pretrained_sft_model_path="$PRETRAINED_MODEL_PATH" \
    dataset.sft_val_dataset_path="$SFT_VAL_DATASET_PATH" \
    training.learning_rate="$LEARNING_RATE" \
    training.batch_size="$BATCH_SIZE" \
    training.accumulation_steps="$ACCUMULATION_STEPS" \
    training.epochs="$EPOCHS" \
    training.zero_stage=3 \
    logging.out_dir="out" \
    logging.save_dir="out"

echo ""
echo "=========================================="
echo "âœ… è®­ç»ƒå®Œæˆ"
echo "=========================================="

