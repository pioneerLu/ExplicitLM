#!/usr/bin/env python3
"""
æµ‹è¯• SFT æ•°æ®åŠ è½½

éªŒè¯è½¬æ¢åçš„ omcq æ•°æ®èƒ½å¦è¢« SFTDataset æ­£ç¡®åŠ è½½
"""

import sys
sys.path.insert(0, '.')

from transformers import AutoTokenizer
from utils.sft_datasets import create_sft_dataloader
from pathlib import Path


def test_sft_data(data_path: str, qwen3_model_path: str):
    """æµ‹è¯• SFT æ•°æ®åŠ è½½"""
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯• SFT æ•°æ®åŠ è½½")
    print("=" * 60)
    
    # åŠ è½½ tokenizer
    print(f"\nğŸ“– åŠ è½½ tokenizer: {qwen3_model_path}")
    try:
        tokenizer = AutoTokenizer.from_pretrained(qwen3_model_path, trust_remote_code=True)
        print("âœ… Tokenizer åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Tokenizer åŠ è½½å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print(f"\nğŸ“Š åˆ›å»ºæ•°æ®åŠ è½½å™¨: {data_path}")
    try:
        train_loader = create_sft_dataloader(
            data_path=data_path,
            tokenizer=tokenizer,
            batch_size=2,
            max_length=512,
            shuffle=False,
            num_workers=0,  # æµ‹è¯•æ—¶ä½¿ç”¨å•è¿›ç¨‹
        )
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œå…± {len(train_loader)} ä¸ªæ‰¹æ¬¡")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡
    print("\nğŸ”„ æµ‹è¯•åŠ è½½ä¸€ä¸ªæ‰¹æ¬¡...")
    try:
        batch = next(iter(train_loader))
        print("âœ… æ‰¹æ¬¡åŠ è½½æˆåŠŸ")
        print(f"  - input_ids shape: {batch['input_ids'].shape}")
        print(f"  - attention_mask shape: {batch['attention_mask'].shape}")
        print(f"  - loss_mask shape: {batch['loss_mask'].shape}")
        print(f"  - labels shape: {batch['labels'].shape}")
        
        # è§£ç ç¬¬ä¸€ä¸ªæ ·æœ¬
        print("\nğŸ“ ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼ˆè§£ç å‰ 100 tokensï¼‰:")
        sample_input_ids = batch['input_ids'][0]
        sample_text = tokenizer.decode(sample_input_ids[:100], skip_special_tokens=False)
        print(f"  {sample_text}...")
        
        return True
    except Exception as e:
        print(f"âŒ æ‰¹æ¬¡åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯• SFT æ•°æ®åŠ è½½")
    parser.add_argument(
        "--data-path",
        type=str,
        default="sft_data/omcq_trex_sft.jsonl",
        help="SFT æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆJSONL æ ¼å¼ï¼‰"
    )
    parser.add_argument(
        "--qwen3-model-path",
        type=str,
        required=True,
        help="Qwen3 æ¨¡å‹è·¯å¾„ï¼ˆç”¨äºåŠ è½½ tokenizerï¼‰"
    )
    
    args = parser.parse_args()
    
    success = test_sft_data(args.data_path, args.qwen3_model_path)
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… æ•°æ®åŠ è½½æµ‹è¯•é€šè¿‡ï¼")
        print("=" * 60)
        sys.exit(0)
    else:
        print("\n" + "=" * 60)
        print("âŒ æ•°æ®åŠ è½½æµ‹è¯•å¤±è´¥ï¼")
        print("=" * 60)
        sys.exit(1)

