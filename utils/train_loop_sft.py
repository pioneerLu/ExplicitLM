"""
SFTè®­ç»ƒå¾ªç¯æ¨¡å—

åŠŸèƒ½ï¼š
- train_epoch_sft: SFTé˜¶æ®µçš„å•ä¸ªepochè®­ç»ƒå¾ªç¯
- eval_model_sft: ç”Ÿæˆå¼è¯„ä¼°å‡½æ•°ï¼ˆæ–‡æœ¬ç”Ÿæˆ+å‡†ç¡®ç‡è®¡ç®—ï¼‰
- judger: æ–‡æœ¬åŒ¹é…è¯„ä¼°å™¨
- æ”¯æŒæ¢¯åº¦ç´¯ç§¯ã€éªŒè¯è¯„ä¼°ã€æ¨¡å‹ä¿å­˜
- é›†æˆSwanLabå®éªŒè¿½è¸ª
"""

import time
from typing import Any, Optional

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from accelerate import Accelerator

from utils.logger import Logger
from utils.train_utils import format_time

try:
    import swanlab
except ImportError:
    swanlab = None


def judger(
    generated_text: str,
    std_output: str,
    judger_mode: str
) -> bool:
    """
    è¯„ä¼°ç”Ÿæˆæ–‡æœ¬ä¸æ ‡å‡†ç­”æ¡ˆçš„åŒ¹é…ç¨‹åº¦

    å‚æ•°ï¼š
        generated_text: ç”Ÿæˆçš„æ–‡æœ¬
        std_output: æ ‡å‡†ç­”æ¡ˆ
        judger_mode: åˆ¤æ–­æ¨¡å¼
            - exact: ç²¾ç¡®åŒ¹é…
            - contains: æ ‡å‡†ç­”æ¡ˆåŒ…å«åœ¨ç”Ÿæˆæ–‡æœ¬ä¸­
            - startswith: ç”Ÿæˆæ–‡æœ¬ä»¥æ ‡å‡†ç­”æ¡ˆå¼€å¤´
            - endswith: ç”Ÿæˆæ–‡æœ¬ä»¥æ ‡å‡†ç­”æ¡ˆç»“å°¾

    è¿”å›ï¼š
        æ˜¯å¦åŒ¹é…æˆåŠŸ
    """
    gen_stripped = generated_text.strip()
    std_stripped = std_output.strip()

    if judger_mode == 'exact':
        return gen_stripped == std_stripped
    elif judger_mode == 'contains':
        return std_stripped in gen_stripped
    elif judger_mode == 'startswith':
        return gen_stripped.startswith(std_stripped)
    elif judger_mode == 'endswith':
        return gen_stripped.endswith(std_stripped)
    return False


def eval_model_sft(
    model: nn.Module,
    eval_loader: DataLoader,
    tokenizer: Any,
    accelerator: Accelerator,
    args: Any,
    judger_mode: str = "startswith"
) -> dict:
    """
    SFTé˜¶æ®µçš„ç”Ÿæˆå¼è¯„ä¼°å‡½æ•°

    å‚æ•°ï¼š
        model: å¾…è¯„ä¼°æ¨¡å‹ï¼ˆwrapped modelï¼‰
        eval_loader: è¯„ä¼°æ•°æ®åŠ è½½å™¨
        tokenizer: Tokenizerå®ä¾‹
        accelerator: Acceleratorå®ä¾‹
        args: é…ç½®å‚æ•°
        judger_mode: åˆ¤æ–­æ¨¡å¼

    è¿”å›ï¼š
        æ€§èƒ½å­—å…¸ï¼ŒåŒ…å«æ¯ä¸ªæ ·æœ¬çš„ç»“æœå’Œæ•´ä½“å‡†ç¡®ç‡

    è¯´æ˜ï¼š
        - æ¨¡å‹ç”Ÿæˆå®Œæ•´å›å¤
        - ä¸æ ‡å‡†ç­”æ¡ˆå¯¹æ¯”ï¼ˆstartswith/containsç­‰ï¼‰
        - è®¡ç®—å‡†ç¡®ç‡æŒ‡æ ‡
    """
    # éªŒè¯ tokenizer é…ç½®
    if tokenizer.eos_token_id is None:
        raise ValueError("tokenizer ç¼ºå°‘ eos_token_id é…ç½®")
    if tokenizer.pad_token_id is None:
        raise ValueError("tokenizer ç¼ºå°‘ pad_token_id é…ç½®")

    # è®¾ç½®è¯„ä¼°æ¨¡å¼ï¼ˆåœ¨ wrapped model ä¸Šæ“ä½œï¼‰
    model.eval()
    performance = {}
    total_correct = 0
    total_steps = 0

    with torch.no_grad():
        for step, batch in enumerate(eval_loader):
            # éªŒè¯ batch size = 1ï¼ˆå½“å‰å®ç°çš„å‡è®¾ï¼‰
            if not (isinstance(batch, tuple) and len(batch) == 2):
                Logger(f"âš ï¸ è¯„ä¼°æ•°æ®æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡ step {step}", accelerator)
                continue

            prompt_input, std_output = batch

            # ç¡®ä¿æ˜¯å•æ ·æœ¬
            if not (isinstance(prompt_input, (list, tuple)) and len(prompt_input) > 0):
                Logger(f"âš ï¸ prompt_input æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡ step {step}", accelerator)
                continue

            prompt_input = prompt_input[0][-args.model.max_seq_len - 1:]
            std_output = std_output[0] if isinstance(std_output, (list, tuple)) else std_output

            # Tokenizeè¾“å…¥
            try:
                x = torch.tensor(
                    tokenizer(prompt_input)['input_ids'],
                    device=accelerator.device
                ).unsqueeze(0)
            except Exception as e:
                Logger(f"âš ï¸ Tokenization å¤±è´¥ (step {step}): {e}", accelerator)
                continue

            # ç”Ÿæˆæ–‡æœ¬ï¼ˆéœ€è¦ unwrap è®¿é—®è‡ªå®šä¹‰æ–¹æ³•ï¼‰
            unwrapped_model = accelerator.unwrap_model(model)

            try:
                generated = unwrapped_model.generate(
                    x,
                    max_new_tokens=getattr(args.training, 'max_new_tokens', 50),
                    max_length=args.model.max_seq_len + getattr(args.training, 'max_new_tokens', 50),
                    temperature=0.7,
                    top_p=0.9,
                    do_sample=True,
                    eos_token_id=tokenizer.eos_token_id,
                    pad_token_id=tokenizer.pad_token_id
                )
            except Exception as e:
                Logger(f"âš ï¸ ç”Ÿæˆå¤±è´¥ (step {step}): {e}", accelerator)
                continue

            # è§£ç ç”Ÿæˆçš„æ–‡æœ¬
            try:
                generated_text = tokenizer.decode(
                    generated.squeeze()[x.shape[1]:].tolist(),
                    skip_special_tokens=True
                )
            except Exception as e:
                Logger(f"âš ï¸ è§£ç å¤±è´¥ (step {step}): {e}", accelerator)
                continue

            # åˆ¤æ–­æ˜¯å¦åŒ¹é…
            generated_text = generated_text.strip()
            flag = judger(generated_text, std_output, judger_mode)

            # ä¿å­˜æ ·æœ¬ç»“æœ
            performance[step] = {
                'prompt': prompt_input,
                'std_output': std_output,
                'generated_text': generated_text,
                'result': flag,
                'judger_mode': judger_mode
            }

            # ç´¯ç§¯ç»Ÿè®¡
            total_correct += int(flag)
            total_steps += 1

            # å®šæœŸæ‰“å°è¯„ä¼°ç»“æœæ ·ä¾‹
            if accelerator.is_main_process and step % max(1, len(eval_loader) // getattr(args.training, 'show_eval_res', 5)) == 0:
                Logger(
                    f"è¯„ä¼°æ ·ä¾‹ Step {step}: "
                    f"ç”Ÿæˆ='{generated_text[:30]}...' | "
                    f"æ ‡å‡†='{std_output[:30]}...' | "
                    f"åŒ¹é…={flag}",
                    accelerator
                )

    # è®¡ç®—æ•´ä½“æ€§èƒ½
    accuracy = total_correct / total_steps if total_steps > 0 else 0.0

    performance['overall'] = {
        'total_steps': total_steps,
        'total_correct': total_correct,
        'accuracy': accuracy
    }

    if accelerator.is_main_process:
        Logger(
            f"ğŸ“Š è¯„ä¼°ç»“æœ: å‡†ç¡®ç‡={accuracy:.4f} ({total_correct}/{total_steps})",
            accelerator
        )

    # æ¢å¤è®­ç»ƒæ¨¡å¼ï¼ˆåœ¨ wrapped model ä¸Šæ“ä½œï¼‰
    model.train()

    return performance


def train_epoch_sft(
    epoch: int,
    accelerator: Accelerator,
    model: nn.Module,
    train_loader: DataLoader,
    optimizer: Any,
    scheduler: Any,
    args: Any,
    overall_start_time: float,
    swanlab_run: Optional[Any],
    tokenizer: Any,
    eval_loader: Optional[DataLoader] = None
) -> None:
    """
    SFTé˜¶æ®µçš„å•ä¸ªepochè®­ç»ƒå¾ªç¯

    å‚æ•°ï¼š
        epoch: å½“å‰epochç¼–å·ï¼ˆä»0å¼€å§‹ï¼‰
        accelerator: Acceleratorå®ä¾‹
        model: è®­ç»ƒæ¨¡å‹ï¼ˆwrapped modelï¼‰
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        args: é…ç½®å‚æ•°ï¼ˆhydra-zenç»“æ„ï¼šargs.training/model/loggingï¼‰
        overall_start_time: æ•´ä½“è®­ç»ƒå¼€å§‹æ—¶é—´
        swanlab_run: SwanLabè¿è¡Œå®ä¾‹
        tokenizer: Tokenizerå®ä¾‹
        eval_loader: è¯„ä¼°æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰

    è¯´æ˜ï¼š
        æ··åˆç²¾åº¦ç”±DeepSpeedé…ç½®æ–‡ä»¶ï¼ˆds_config.jsonï¼‰è‡ªåŠ¨æ§åˆ¶
        - bf16å·²å¯ç”¨ï¼Œæ— éœ€æ‰‹åŠ¨åˆ›å»ºautocastä¸Šä¸‹æ–‡
        - æ¢¯åº¦ç´¯ç§¯ç”±DeepSpeedè‡ªåŠ¨å¤„ç†
        - æ¢¯åº¦è£å‰ªç”±DeepSpeedè‡ªåŠ¨å¤„ç†

        è¯„ä¼°æ–¹å¼ï¼š
        - ä½¿ç”¨eval_model_sftè¿›è¡Œç”Ÿæˆå¼è¯„ä¼°
        - è®¡ç®—æ–‡æœ¬ç”Ÿæˆå‡†ç¡®ç‡
        - é€‚ç”¨äºSFTé˜¶æ®µçš„å¯¹è¯è´¨é‡è¯„ä¼°
    """
    loss_fct = nn.CrossEntropyLoss(reduction='none')
    epoch_start_time = time.time()
    total_steps_in_epoch = len(train_loader)
    total_training_steps = args.training.epochs * total_steps_in_epoch
    moe_path = '_moe' if args.model.use_moe else ''
    best_loss = float('inf')
    best_accuracy = 0.0

    # è®°å½•åˆå§‹çŠ¶æ€
    last_log_time = epoch_start_time

    for step, (X, Y, loss_mask) in enumerate(train_loader):
        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler is not None:
            scheduler.step()

        # å‰å‘ä¼ æ’­ï¼ˆDeepSpeedè‡ªåŠ¨å¤„ç†bf16æ··åˆç²¾åº¦ï¼‰
        res = model(X, step=step)

        # è®¡ç®—ä¸»è¦æŸå¤±ï¼ˆäº¤å‰ç†µæŸå¤±ï¼‰
        ce_loss = loss_fct(
            res.logits.view(-1, res.logits.size(-1)),
            Y.view(-1)
        ).view(Y.size())
        ce_loss = (ce_loss * loss_mask).sum() / loss_mask.sum()

        # å¤„ç†è¾…åŠ©æŸå¤±
        similarity_loss = 0
        diversity_loss = 0

        if hasattr(res, 'aux_loss') and res.aux_loss is not None:
            aux_loss = res.aux_loss
            if isinstance(aux_loss, dict):
                # ä¸‰æŸå¤±ç»“æ„
                similarity_loss = aux_loss.get('similarity_loss', 0)
                diversity_loss = aux_loss.get('diversity_loss', 0)

                # åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„æŸå¤±èšåˆ
                if isinstance(similarity_loss, torch.Tensor):
                    similarity_loss = accelerator.gather(similarity_loss).mean()
                if isinstance(diversity_loss, torch.Tensor):
                    diversity_loss = accelerator.gather(diversity_loss).mean()

        # ä¸‰æŸå¤±ç³»ç»Ÿï¼šCE + Similarity + Diversity
        similarity_coef = getattr(args.training, 'similarity_loss_coef', 0.1)
        diversity_coef = getattr(args.training, 'diversity_loss_coef', 0.05)

        total_loss = (
            ce_loss +
            similarity_coef * similarity_loss +
            diversity_coef * diversity_loss
        )
        loss = total_loss / args.training.accumulation_steps

        # åå‘ä¼ æ’­
        accelerator.backward(loss)

        # ä¼˜åŒ–å™¨æ­¥éª¤
        optimizer.step()
        optimizer.zero_grad()

        # VQ-VAEé£æ ¼çš„EMAæ›´æ–°ï¼ˆä»…åœ¨å¯ç”¨æ—¶æ‰§è¡Œï¼‰
        if hasattr(res, 'ema_stats') and res.ema_stats is not None:
            unwrapped_model = accelerator.unwrap_model(model)
            if hasattr(unwrapped_model, 'apply_ema_update'):
                ema_update_stats = unwrapped_model.apply_ema_update(res.ema_stats)

                # è®°å½•EMAæ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                if (step + 1) % args.logging.log_interval == 0 and accelerator.is_main_process:
                    if ema_update_stats.get('ema_update_applied', False):
                        total_memories = args.model.knowledge_num
                        Logger(
                            f"EMAæ›´æ–° - Step: {ema_update_stats['ema_step']}, "
                            f"æ›´æ–°è®°å¿†æ•°: {ema_update_stats['updated_memories']}/{total_memories} "
                            f"({ema_update_stats['update_ratio']:.4f}), "
                            f"è¦†ç›–ç‡: {ema_update_stats['selected_memory_coverage']:.4f}",
                            accelerator
                        )

        # è®­ç»ƒæ—¥å¿—è®°å½•ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        if (step + 1) % args.logging.log_interval == 0 and accelerator.is_main_process:
            current_time = time.time()

            # è®¡ç®—å½“å‰å­¦ä¹ ç‡
            current_lr = optimizer.param_groups[0]['lr']

            # è®¡ç®—æ—¶é—´ä¼°ç®—
            epoch_elapsed_time = current_time - epoch_start_time
            epoch_steps_done = step + 1
            epoch_avg_step_time = epoch_elapsed_time / epoch_steps_done
            epoch_remaining_time = epoch_avg_step_time * (total_steps_in_epoch - epoch_steps_done)

            total_elapsed_time = current_time - overall_start_time
            total_steps_done = epoch * total_steps_in_epoch + epoch_steps_done
            total_avg_step_time = total_elapsed_time / total_steps_done if total_steps_done > 0 else 0
            total_remaining_time = total_avg_step_time * (total_training_steps - total_steps_done) if total_steps_done > 0 else 0

            # è®¡ç®—è®­ç»ƒé€Ÿåº¦
            interval_elapsed_time = current_time - last_log_time
            tokens_processed_interval = args.logging.log_interval * args.training.batch_size * args.model.max_seq_len
            tokens_per_sec = tokens_processed_interval / interval_elapsed_time if interval_elapsed_time > 0 else 0
            last_log_time = current_time

            # è·å–è®°å¿†åº“æ›´æ–°ç»Ÿè®¡ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
            memory_update_stats = {}
            unwrapped_model = accelerator.unwrap_model(model)
            if hasattr(unwrapped_model, 'get_memory_update_stats'):
                try:
                    memory_update_stats = unwrapped_model.get_memory_update_stats()
                except Exception as e:
                    Logger(f"è·å–è®°å¿†æ›´æ–°ç»Ÿè®¡å¤±è´¥: {e}", accelerator)

            # è·å–ä½™å¼¦ç›¸ä¼¼åº¦ç»Ÿè®¡
            avg_selected_similarity = 0.0
            if hasattr(res, 'cosine_stats') and res.cosine_stats is not None:
                cosine_stats = res.cosine_stats
                selected_similarities = [
                    v for k, v in cosine_stats.items()
                    if k.endswith('_selected_avg_similarity')
                ]
                if selected_similarities:
                    import numpy as np
                    avg_selected_similarity = np.mean(selected_similarities)

            # æ„å»ºæ—¥å¿—å­—å…¸
            log_dict = {
                "epoch": epoch + 1,
                "step": step + 1,
                "total_steps_in_epoch": total_steps_in_epoch,
                "train/loss_ce": ce_loss.item(),
                "train/loss_similarity": similarity_loss.item() if isinstance(similarity_loss, torch.Tensor) else similarity_loss,
                "train/loss_diversity": diversity_loss.item() if isinstance(diversity_loss, torch.Tensor) else diversity_loss,
                "train/loss_total": total_loss.item(),
                "lr": current_lr,
                "tokens_per_sec": tokens_per_sec,
                "epoch_time_left_seconds": epoch_remaining_time,
                "total_time_left_seconds": total_remaining_time,
                "train/avg_selected_similarity": avg_selected_similarity,
            }

            # æ·»åŠ è®°å¿†åº“æ›´æ–°ç»Ÿè®¡
            log_dict.update(memory_update_stats)

            # æ§åˆ¶å°è¾“å‡º
            Logger(
                f"Epoch {epoch+1}/{args.training.epochs}, Step {step+1}/{total_steps_in_epoch}, "
                f"CE: {log_dict['train/loss_ce']:.4f}, "
                f"Sim: {log_dict['train/loss_similarity']:.4f}, "
                f"Div: {log_dict['train/loss_diversity']:.4f}, "
                f"Total: {log_dict['train/loss_total']:.4f}, "
                f"LR: {log_dict['lr']:.6f}, "
                f"Speed: {log_dict['tokens_per_sec']:.2f} tokens/sec | "
                f"Sel.Sim: {avg_selected_similarity:.4f} | "
                f"Epochå‰©ä½™: {format_time(epoch_remaining_time)} | "
                f"æ€»å‰©ä½™: {format_time(total_remaining_time)}",
                accelerator
            )

            # SwanLabæ—¥å¿—è®°å½•
            if args.logging.use_swanlab and swanlab_run:
                swanlab_run.log(log_dict)

        # SFTç”Ÿæˆå¼è¯„ä¼°ï¼ˆå®šæœŸæ‰§è¡Œï¼‰
        eval_interval = getattr(args.training, 'eval_interval', 1000)
        start_eval = getattr(args.training, 'start_eval', 100)

        if (step + 1) % eval_interval == 0:
            if (step + 1) >= start_eval and eval_loader is not None:
                if accelerator.is_main_process:
                    Logger(f"ğŸ” å¼€å§‹SFTç”Ÿæˆå¼è¯„ä¼°...", accelerator)

                performance = eval_model_sft(
                    model=model,
                    eval_loader=eval_loader,
                    tokenizer=tokenizer,
                    accelerator=accelerator,
                    args=args,
                    judger_mode=getattr(args.training, 'judger_mode', 'startswith')
                )

                # è®°å½•è¯„ä¼°æŒ‡æ ‡åˆ°SwanLab
                if accelerator.is_main_process and args.logging.use_swanlab and swanlab_run:
                    swanlab_run.log({
                        "val/eval_accuracy": performance['overall']['accuracy'],
                        "val/eval_total_steps": performance['overall']['total_steps'],
                        "val/eval_total_correct": performance['overall']['total_correct']
                    })

                # åŸºäºå‡†ç¡®ç‡ä¿å­˜æœ€ä½³æ¨¡å‹
                current_accuracy = performance['overall']['accuracy']
                if current_accuracy > best_accuracy:
                    best_accuracy = current_accuracy
                    if accelerator.is_main_process:
                        ckp = f'{args.logging.save_dir}/sft_best_acc_{args.model.dim}{moe_path}.pth'
                        unwrapped_model = accelerator.unwrap_model(model)
                        accelerator.save(unwrapped_model.state_dict(), ckp)
                        Logger(f"âœ… æœ€ä½³å‡†ç¡®ç‡æ¨¡å‹å·²ä¿å­˜è‡³ {ckp} (acc={best_accuracy:.4f})", accelerator)

        # åŸºäºæŸå¤±ä¿å­˜æ¨¡å‹ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        if accelerator.is_main_process:
            loss_total = loss.item() * args.training.accumulation_steps
            if best_loss > loss_total:
                best_loss = loss_total
                ckp = f'{args.logging.save_dir}/sft_{args.model.dim}{moe_path}.pth'

                # è·å–è§£åŒ…åçš„æ¨¡å‹
                unwrapped_model = accelerator.unwrap_model(model)

                # ä¿å­˜æ¨¡å‹å‚æ•°
                accelerator.save(unwrapped_model.state_dict(), ckp)
                Logger(f"âœ… æœ€ä½³æŸå¤±æ¨¡å‹å·²ä¿å­˜è‡³ {ckp} (loss={best_loss:.4f})", accelerator)
