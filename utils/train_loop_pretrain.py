"""
è®­ç»ƒå¾ªç¯æ¨¡å—

åŠŸèƒ½ï¼š
- train_epoch: å•ä¸ªepochçš„è®­ç»ƒå¾ªç¯
- æ”¯æŒæ¢¯åº¦ç´¯ç§¯ã€éªŒè¯è¯„ä¼°ã€æ¨¡å‹ä¿å­˜
- é›†æˆSwanLabå®éªŒè¿½è¸ª
"""

import os
import json
import time
from typing import Any, Optional

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from accelerate import Accelerator

from utils.logger import Logger
from utils.train_utils import validate_model, format_time

try:
    import swanlab
except ImportError:
    swanlab = None


def train_epoch(
    epoch: int,
    accelerator: Accelerator,
    model: nn.Module,
    train_loader: DataLoader,
    optimizer: Any,
    scheduler: Any,
    args: Any,
    overall_start_time: float,
    swanlab_run: Optional[Any],
    tokenizer: Any,
    val_loader: Optional[DataLoader] = None,
    resume_step: int = 0  # [æ–°å¢] æ¥æ”¶éœ€è¦è·³è¿‡çš„æ­¥æ•°
) -> None:
    """
    å•ä¸ªepochçš„è®­ç»ƒå¾ªç¯

    å‚æ•°ï¼š
        epoch: å½“å‰epochç¼–å·ï¼ˆä»0å¼€å§‹ï¼‰
        accelerator: Acceleratorå®ä¾‹
        model: è®­ç»ƒæ¨¡å‹
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        optimizer: ä¼˜åŒ–å™¨
        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨
        args: é…ç½®å‚æ•°
        overall_start_time: æ•´ä½“è®­ç»ƒå¼€å§‹æ—¶é—´
        swanlab_run: SwanLabè¿è¡Œå®ä¾‹
        tokenizer: Tokenizerå®ä¾‹
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨ï¼ˆå¯é€‰ï¼‰

    è¯´æ˜ï¼š
        æ··åˆç²¾åº¦ç”±DeepSpeedé…ç½®æ–‡ä»¶ï¼ˆds_config.jsonï¼‰è‡ªåŠ¨æ§åˆ¶
        - bf16å·²å¯ç”¨ï¼Œæ— éœ€æ‰‹åŠ¨åˆ›å»ºautocastä¸Šä¸‹æ–‡
        - æ¢¯åº¦ç´¯ç§¯ç”±DeepSpeedè‡ªåŠ¨å¤„ç†
        - æ¢¯åº¦è£å‰ªç”±DeepSpeedè‡ªåŠ¨å¤„ç†
    """
    loss_fct = nn.CrossEntropyLoss(reduction='none')
    epoch_start_time = time.time()
    
    # è®¡ç®—æ€»æ­¥æ•°ä¿¡æ¯
    total_steps_in_epoch = len(train_loader)
    total_training_steps = args.training.epochs * total_steps_in_epoch
    
    moe_path = '_moe' if args.model.use_moe else ''
    best_loss = float('inf') # æ³¨æ„ï¼šè¿™é‡Œbest_lossæ˜¯epochå†…å±€éƒ¨æœ€ä¼˜ï¼Œå¦‚æœéœ€è¦å…¨å±€æœ€ä¼˜éœ€è¦åœ¨å¤–éƒ¨ç»´æŠ¤å¹¶ä¼ å…¥

    # [æ–°å¢] æ–­ç‚¹ç»­è®­ï¼šè·³è¿‡å·²è®­ç»ƒçš„ batches
    if resume_step > 0:
        train_loader = accelerator.skip_first_batches(train_loader, num_batches=resume_step)
        if accelerator.is_main_process:
            Logger(f"Epoch {epoch}: å·²è·³è¿‡å‰ {resume_step} ä¸ª batches ä»¥å®ç°ç»­è®­", accelerator)

    # è®°å½•åˆå§‹çŠ¶æ€
    last_log_time = time.time()

    # ä½¿ç”¨ enumerate è·å–å½“å‰å¾ªç¯çš„ç´¢å¼• step_idx
    for step_idx, (X, Y, loss_mask) in enumerate(train_loader):
        # [æ–°å¢] è®¡ç®—å½“å‰ epoch å†…çš„çœŸå® step å’Œå…¨å±€ step
        current_step = step_idx + resume_step
        global_step = epoch * total_steps_in_epoch + current_step + 1

        # æ›´æ–°å­¦ä¹ ç‡
        if scheduler is not None:
            scheduler.step()

        # å‰å‘ä¼ æ’­ï¼ˆDeepSpeedè‡ªåŠ¨å¤„ç†bf16æ··åˆç²¾åº¦ï¼‰
        # ç¬¬ä¸€ä¸ªepochçš„embeddingå†»ç»“å¤„ç† (ä½¿ç”¨ current_step åˆ¤æ–­)
        if current_step == 0 and args.training.embeddings_epoch == epoch:
            unwrapped_model = accelerator.unwrap_model(model)
            unwrapped_model.freeze_embedding = True
            Logger(f"è®¾ç½®freeze_embedding=True (epoch {epoch}, step {current_step})", accelerator)

        res = model(X, step=current_step) # ä¼ å…¥æ­£ç¡®çš„ step

        # è®¡ç®—ä¸»è¦æŸå¤±ï¼ˆäº¤å‰ç†µæŸå¤±ï¼‰
        ce_loss = loss_fct(
            res.logits.view(-1, res.logits.size(-1)),
            Y.view(-1)
        ).view(Y.size())
        ce_loss = (ce_loss * loss_mask).sum() / loss_mask.sum()

        # å¤„ç†è¾…åŠ©æŸå¤±
        similarity_loss = 0
        diversity_loss = 0

        if hasattr(res, 'aux_loss') and res.aux_loss is not None:
            aux_loss = res.aux_loss
            if isinstance(aux_loss, dict):
                # ä¸‰æŸå¤±ç»“æ„
                similarity_loss = aux_loss.get('similarity_loss', 0)
                diversity_loss = aux_loss.get('diversity_loss', 0)

                # åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„æŸå¤±èšåˆ
                if isinstance(similarity_loss, torch.Tensor):
                    similarity_loss = accelerator.gather(similarity_loss).mean()
                if isinstance(diversity_loss, torch.Tensor):
                    diversity_loss = accelerator.gather(diversity_loss).mean()

        # ä¸‰æŸå¤±ç³»ç»Ÿï¼šCE + Similarity + Diversity
        similarity_coef = getattr(args, 'similarity_loss_coef', 0.1)
        diversity_coef = getattr(args, 'diversity_loss_coef', 0.05)

        total_loss = (
            ce_loss +
            similarity_coef * similarity_loss +
            diversity_coef * diversity_loss
        )
        loss = total_loss / args.training.accumulation_steps

        # åå‘ä¼ æ’­
        accelerator.backward(loss)

        # ä¼˜åŒ–å™¨æ­¥éª¤
        optimizer.step()
        optimizer.zero_grad()

        # Memory bankåœ¨è®­ç»ƒæ—¶å›ºå®šï¼Œæ¨ç†æ—¶é€šè¿‡LLMLinguaæ›´æ–°ï¼Œä¸å†éœ€è¦EMAæ›´æ–°

        # ============================================================
        # [æ–°å¢] æœºåˆ¶1ï¼šæ¯ 500 ä¸ª Global Step ä¿å­˜ä¸€æ¬¡å®Œæ•´ Checkpoint (ç”¨äºç»­è®­)
        # ============================================================
        SAVE_INTERVAL = 500  # å¯ä»¥æ”¹ä¸ºä» args ä¼ å…¥: args.training.save_interval
        if global_step % SAVE_INTERVAL == 0:
            save_dir = os.path.join(args.logging.save_dir, f"checkpoint_step_{global_step}")
            if accelerator.is_main_process:
                os.makedirs(save_dir, exist_ok=True)
            
            # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹ï¼Œç¡®ä¿å®‰å…¨ä¿å­˜
            accelerator.wait_for_everyone()
            # ä¿å­˜å®Œæ•´çŠ¶æ€ (æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€LRè°ƒåº¦å™¨ç­‰)
            accelerator.save_state(save_dir)
            
            # ä»…ä¸»è¿›ç¨‹å†™å…¥å…ƒæ•°æ®ï¼Œè®°å½•ç²¾ç¡®çš„æ¢å¤ä½ç½®
            if accelerator.is_main_process:
                with open(os.path.join(save_dir, "training_state.json"), "w") as f:
                    # è®°å½•å½“å‰å®Œæˆçš„ stepï¼Œæ¢å¤æ—¶åº”ä» current_step + 1 å¼€å§‹
                    json.dump({
                        "epoch": epoch, 
                        "step": current_step, 
                        "global_step": global_step
                    }, f)
                Logger(f"ğŸ”¥ [Checkpoint] Step {global_step} å®Œæ•´çŠ¶æ€å·²ä¿å­˜è‡³ {save_dir}", accelerator)

        # ============================================================
        # éªŒè¯è¯„ä¼°å’Œæ—¥å¿—è®°å½•ï¼ˆä»…ä¸»è¿›ç¨‹ï¼‰
        # ============================================================
        if (current_step + 1) % args.logging.log_interval == 0 and accelerator.is_main_process:
            current_time = time.time()
            current_lr = optimizer.param_groups[0]['lr']

            # æ—¶é—´ä¼°ç®—
            epoch_elapsed = current_time - epoch_start_time
            # å½“å‰epochå·²å®Œæˆçš„stepæ•° (åŒ…å«è·³è¿‡çš„)
            epoch_steps_done = current_step + 1
            # æ³¨æ„ï¼šå¦‚æœè·³è¿‡äº†å¾ˆå¤šæ­¥ï¼ŒåˆæœŸä¼°ç®—å¯èƒ½ä¸å‡†ï¼Œä½†ä¼šè¿…é€Ÿæ”¶æ•›
            epoch_avg_time = epoch_elapsed / (epoch_steps_done - resume_step) if (epoch_steps_done - resume_step) > 0 else 0
            epoch_remaining = epoch_avg_time * (total_steps_in_epoch - epoch_steps_done)

            total_elapsed = current_time - overall_start_time
            total_steps_done = global_step
            total_avg_time = total_elapsed / total_steps_done if total_steps_done > 0 else 0
            total_remaining = total_avg_time * (total_training_steps - total_steps_done)

            # è®¡ç®—è®­ç»ƒé€Ÿåº¦
            interval_time = current_time - last_log_time
            tokens_processed = args.logging.log_interval * args.training.batch_size * args.model.max_seq_len
            tokens_per_sec = tokens_processed / interval_time if interval_time > 0 else 0
            last_log_time = current_time

            # æ‰§è¡ŒéªŒè¯è¯„ä¼°
            val_loss = None
            if val_loader is not None:
                try:
                    val_loss = validate_model(model, val_loader, loss_fct, accelerator)
                    Logger(f"éªŒè¯æŸå¤±: {val_loss:.4f}", accelerator)
                except Exception as e:
                    Logger(f"éªŒè¯è¯„ä¼°å¤±è´¥: {e}", accelerator)
                    val_loss = None

            # è·å–è®°å¿†åº“æ›´æ–°ç»Ÿè®¡ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
            memory_update_stats = {}
            unwrapped_model = accelerator.unwrap_model(model)
            if hasattr(unwrapped_model, 'get_memory_update_stats'):
                try:
                    memory_update_stats = unwrapped_model.get_memory_update_stats()
                except Exception as e:
                    Logger(f"è·å–è®°å¿†æ›´æ–°ç»Ÿè®¡å¤±è´¥: {e}", accelerator)

            # è·å–ä½™å¼¦ç›¸ä¼¼åº¦ç»Ÿè®¡
            avg_selected_similarity = 0.0
            if hasattr(res, 'cosine_stats') and res.cosine_stats is not None:
                cosine_stats = res.cosine_stats
                selected_similarities = [
                    v for k, v in cosine_stats.items()
                    if k.endswith('_selected_avg_similarity')
                ]
                if selected_similarities:
                    import numpy as np
                    avg_selected_similarity = np.mean(selected_similarities)

            # æ„å»ºæ—¥å¿—å­—å…¸
            log_dict = {
                "epoch": epoch + 1,
                "step": current_step + 1,
                "global_step": global_step,
                "train/loss_ce": ce_loss.item(),
                "train/loss_similarity": similarity_loss.item() if isinstance(similarity_loss, torch.Tensor) else similarity_loss,
                "train/loss_diversity": diversity_loss.item() if isinstance(diversity_loss, torch.Tensor) else diversity_loss,
                "train/loss_total": total_loss.item(),
                "lr": current_lr,
                "tokens_per_sec": tokens_per_sec,
                "epoch_time_left": epoch_remaining,
                "total_time_left": total_remaining,
                "train/avg_selected_similarity": avg_selected_similarity,
            }

            # æ·»åŠ éªŒè¯æŸå¤±
            if val_loss is not None:
                log_dict["val/loss"] = val_loss

            # æ·»åŠ è®°å¿†åº“æ›´æ–°ç»Ÿè®¡
            log_dict.update(memory_update_stats)

            # æ§åˆ¶å°è¾“å‡º
            Logger(
                f"Epoch {epoch+1}/{args.training.epochs} | Step {current_step+1}/{total_steps_in_epoch} (Global {global_step}) | "
                f"Loss: {total_loss.item():.4f} | Val: {log_dict.get('val/loss', 'N/A')} | "
                f"CE: {ce_loss.item():.4f} | Sim: {similarity_loss.item():.4f} | Div: {diversity_loss.item():.4f} | "
                f"Speed: {tokens_per_sec:.0f} tok/s | "
                f"ETA Epoch: {format_time(epoch_remaining)}",
                accelerator
            )

            # SwanLabæ—¥å¿—è®°å½•
            if args.logging.use_swanlab and swanlab_run:
                swanlab_run.log(log_dict)

        # ============================================================
        # [åŸæœ‰] æœºåˆ¶2ï¼šä¿å­˜å½“å‰ Epoch å†…æœ€ä½³æƒé‡ (ç”¨äºæ¨ç†)
        # ============================================================
        # æ³¨æ„ï¼šè¿™é‡Œä»…åœ¨ä¸»è¿›ç¨‹æ‰§è¡Œï¼Œä¸”åªä¿å­˜æƒé‡(state_dict)ï¼Œä¸åŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€
        if accelerator.is_main_process:
            current_loss_total = loss.item() * args.training.accumulation_steps
            if best_loss > current_loss_total:
                best_loss = current_loss_total
                # æ„é€ ä¿å­˜è·¯å¾„ï¼Œå»ºè®®åŠ ä¸Š epoch ä»¥å…ä¸åŒ epoch çš„æœ€ä½³æ¨¡å‹äº’ç›¸è¦†ç›–(å¯é€‰)
                # åŸè·¯å¾„: f'{args.logging.save_dir}/pretrain_{args.model.dim}{moe_path}.pth'
                # å»ºè®®æ”¹è¿›è·¯å¾„:
                ckp_best = f'{args.logging.save_dir}/pretrain_{args.model.dim}_epoch{epoch}{moe_path}_best.pth'

                unwrapped_model = accelerator.unwrap_model(model)
                accelerator.save(unwrapped_model.state_dict(), ckp_best)
                # Logger(f"ğŸŒŸ æ–°æœ€ä½³æ¨¡å‹ (Loss {best_loss:.4f}) å·²ä¿å­˜è‡³ {ckp_best}", accelerator) 
                # æ³¨ï¼šå¦‚æœæ¯ä¸ªstepéƒ½æ‰“å°å¯èƒ½ä¼šå¤ªå¤šï¼Œå¯ä»¥è€ƒè™‘åªåœ¨ log_interval æ—¶æ‰“å°
