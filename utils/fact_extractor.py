"""
äº‹å®æå–å™¨ï¼šä½¿ç”¨ LLMLingua ä»è¾“å…¥æ–‡æœ¬ä¸­æå–æµ“ç¼©äº‹å®
"""
import os
from typing import List, Dict, Optional, Tuple
import torch
from pathlib import Path

try:
    from llmlingua import PromptCompressor
    LLMLINGUA_AVAILABLE = True
except ImportError:
    LLMLINGUA_AVAILABLE = False
    print("âš ï¸  llmlingua æœªå®‰è£…ï¼Œäº‹å®æå–åŠŸèƒ½å°†ä¸å¯ç”¨")


class FactExtractor:
    """ä½¿ç”¨ LLMLingua æå–æµ“ç¼©äº‹å®"""
    
    def __init__(
        self,
        model_path: str = "/data2/zengzheni/lvchangwei/new_repo/bert/llmlingua-2-bert",
        compression_rate: float = 0.4,  # å‹ç¼©åˆ°40%ï¼Œä¿ç•™60%çš„å…³é”®ä¿¡æ¯
        force_tokens: Optional[List[str]] = None,
        chunk_end_tokens: Optional[List[str]] = None,
        device: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ–äº‹å®æå–å™¨
        
        Args:
            model_path: LLMLingua æ¨¡å‹è·¯å¾„
            compression_rate: å‹ç¼©ç‡ï¼ˆ0-1ï¼‰ï¼Œè¶Šå°ä¿ç•™çš„ä¿¡æ¯è¶Šå¤š
            force_tokens: å¼ºåˆ¶ä¿ç•™çš„tokenåˆ—è¡¨ï¼ˆå¦‚æ ‡ç‚¹ç¬¦å·ï¼‰
            chunk_end_tokens: åˆ†å—ç»“æŸtokenåˆ—è¡¨
            device: è¿è¡Œè®¾å¤‡
        """
        if not LLMLINGUA_AVAILABLE:
            raise ImportError("llmlingua æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install llmlingua")
        
        self.model_path = model_path
        self.compression_rate = compression_rate
        self.force_tokens = force_tokens or ['\n', '.', '!', '?', ',', ':', ';']
        self.chunk_end_tokens = chunk_end_tokens or ['.', '\n', '!', '?']
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        # åˆå§‹åŒ– LLMLingua
        self._init_compressor()
    
    def _init_compressor(self):
        """åˆå§‹åŒ– PromptCompressor"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(
                f"LLMLingua æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}\n"
                f"è¯·è¿è¡Œ bert/get_model.py ä¸‹è½½æ¨¡å‹"
            )
        
        print(f"ğŸ”¤ åŠ è½½ LLMLingua æ¨¡å‹: {self.model_path}")
        self.compressor = PromptCompressor(
            model_name=self.model_path,
            use_llmlingua2=True
        )
        print("âœ… LLMLingua æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def extract_facts(
        self,
        text: str,
        return_annotations: bool = False,
    ) -> Dict[str, any]:
        """
        ä»æ–‡æœ¬ä¸­æå–æµ“ç¼©äº‹å®
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            return_annotations: æ˜¯å¦è¿”å›æ ‡æ³¨ä¿¡æ¯ï¼ˆå“ªäº›tokenè¢«ä¿ç•™/åˆ é™¤ï¼‰
        
        Returns:
            {
                'compressed_text': str,  # å‹ç¼©åçš„æ–‡æœ¬ï¼ˆæµ“ç¼©äº‹å®ï¼‰
                'original_tokens': int,  # åŸå§‹tokenæ•°
                'compressed_tokens': int,  # å‹ç¼©åtokenæ•°
                'compression_ratio': float,  # å‹ç¼©æ¯”ä¾‹
                'annotations': List[Tuple[str, str]],  # (word, label) åˆ—è¡¨ï¼Œlabelä¸º'+'æˆ–'-'
            }
        """
        if not text or not text.strip():
            return {
                'compressed_text': '',
                'original_tokens': 0,
                'compressed_tokens': 0,
                'compression_ratio': 0.0,
                'annotations': [],
            }
        
        try:
            results = self.compressor.compress_prompt_llmlingua2(
                text,
                rate=self.compression_rate,
                force_tokens=self.force_tokens,
                chunk_end_tokens=self.chunk_end_tokens,
                return_word_label=return_annotations,
                drop_consecutive=True,
            )
            
            # è§£ææ ‡æ³¨ä¿¡æ¯
            annotations = []
            if return_annotations and "fn_labeled_original_prompt" in results:
                word_sep = "\t\t|\t\t"
                label_sep = " "
                lines = results["fn_labeled_original_prompt"].split(word_sep)
                for line in lines:
                    if label_sep in line:
                        parts = line.split(label_sep, 1)
                        if len(parts) == 2:
                            word, label = parts
                            annotations.append((word, '+' if label == '1' else '-'))
            
            return {
                'compressed_text': results.get('compressed_prompt', ''),
                'original_tokens': results.get('origin_tokens', 0),
                'compressed_tokens': results.get('compressed_tokens', 0),
                'compression_ratio': results.get('rate', 0.0),
                'annotations': annotations,
            }
        except Exception as e:
            print(f"âš ï¸  äº‹å®æå–å¤±è´¥: {e}")
            # å¤±è´¥æ—¶è¿”å›åŸå§‹æ–‡æœ¬
            return {
                'compressed_text': text,
                'original_tokens': len(text.split()),
                'compressed_tokens': len(text.split()),
                'compression_ratio': 1.0,
                'annotations': [],
            }
    
    def extract_facts_batch(
        self,
        texts: List[str],
        return_annotations: bool = False,
    ) -> List[Dict[str, any]]:
        """æ‰¹é‡æå–äº‹å®"""
        return [self.extract_facts(text, return_annotations) for text in texts]

